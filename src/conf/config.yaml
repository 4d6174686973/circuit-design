### Data setup ###
N_qubits: 9                     # number of qubits
dataset: BAS                    # BAS, JGB
train_split: 0.8                # pct of trainset samples between 0 and 1
width: 3                        # width of the BAS image
height: 3                       # height of the BAS image
N_features: 3                   # number of features for JGB dataset, 3 or 4

### IBM setup ###
simulator: aer_statevec_cpu     # aer_statevec_cpu, aer_kawasaki
transpiler: service             # local or service (not used in statevector simulation)
optimization_level: 3           # optimization for running the quantum circuit: 0, 1, 2, 3 (not used in statevector simulation)
ai_transpiler: True             # True or False (not used in statevector simulation)

### MPS setup ###
cutoff: 5.0e-05                 # cutoff precision for the MPS
descenting_step_length: 0.05    # step length for the descent
descent_steps: 10               # number of steps for the descent
train_loops: 10                 # number of loops for training 

### Circuit setup ###
extension: metric_based         # none, all_to_all, nearest_neighbor, metric_based, random
N_random_extensions: 10         # number of random extensions to compare with metric_based: 10 for BAS, 13 for JGB
random_seed: 42                 # seed for random extension, important for multirun!
extension_metric: hamming       # hamming, varinfo
extension_threshhold: 0.5       # 0.5 for BAS + hamming, 0.95 for JGB + varinfo

### QCBM setup ###
iterations: 10                  # number of training iterations  
batchsize: 1000                 # 0 for using the full train set or positive integer for mini-batch size
N_shots: 1000                   # number of shots in sampling
loss_func: MMD                  # MMD, KL (KL not working yet)
sigmas: [1.0]                   # Bandwidth for MMD Kernel
kernel_multithreading: False    # True or False, for small datasets like BAS False should be faster (not fully tested)
finite_diff_epsilon: 1.0e-8     # epsilon used in finite difference sampling for KL (does not work yet)
adam_learning_rate: 0.01        # initial learning rate for ADAM
